
# CalTRACK Beta Test Data Preparation Guidelines

After cleaning and conducting quality checks on the data for the CalTRACK Beta test, the working group recommends the following processes be followed when loading consumption and project data into an EEmetering evaluation tool. 
It is worth noting that the Beta testers initially received the same data from PG&E (consumption) and Build it Green (projects) and tried to arrive at the same set of outputs for making savings calculations. However, despite multiple attempts at reconciliation, the Beta testers were unable to fully match their processes to produce identical outputs. Instead, for the remainder of the testing process, a subset of data generated by Open Energy Efficiency was used by the Beta testers in order to ensure that methods implementations could be effectively compared.

### *Data Cleaning* 

A full accounting of the data cleaning and processing steps that were required for the purposes of the Beta test can be found here. General guidance suggests that data cleaning processes should be well documented and reviewed. There are countless small decisions that must be made as edge cases in the data arise. Thorough documentation ensures that evaluators understand the implications of these choices. Below are guidelines for the most common issues that arise during data cleaning efforts, based on the experience of the Beta testers during the CalTRACK testing process.

### *Deduplication*

- If a home appears multiple times within a project database, and the project dates are the same the most complete record for that home should be used
- If a home appears multiple times within a project database and the project dates differ because there are multiple measures installed associated with the same incentive program, the start date of the intervention should be the earliest of the project start dates across projects and the end date for the intervention should be the latest of the project end dates.
- If two duplicate records have identical consumption traces and date ranges, drop one at random
- If two duplicate records have identical consumption traces but different date ranges select the more complete record having more dates. - If the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.
- If the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.


### Creating Work Start and Work End dates from raw project data

Accurately identifying baseline and reporting periods is important for reducing the modeling error associated with a savings calculation. However, we have observed considerable variation in database records identifying dates associated with project start and project completion.
In general, our guidance is to try to identify the fields in a project record that most closely match the actual work start and work completion dates. In the absence of either of these fields (that is, if a project record only contains one or the other set of dates), we recommend identifying an average time to completion.
For the Beta test data, we worked with the program implementer to find the best proxy for work start and work finish dates. An initial version of the project data required estimation of some dates, but an updated version contained a complete set of work start and stop dates for all of the projects.


### *Missing Values & Imputation*

**Weather**

Weather data is notoriously incomplete, especially at the granular sub-daily level. Some weather stations generally fail to report data, other weather stations are simply inconsistent in reporting data. This becomes an issue when trying to match projects to their local weather conditions. If a nearby non-reporting weather station is selected, the savings model will fail. If the project is connected to a nearby intermittently reporting weather station, the model will suffer. Additionally, if a project is connected to a weather station that experiences a significantly different local micro-climate, the model will suffer or fail.

For the purposes of the Beta test, we adopted the following rules, which we also support as general guidelines for dealing with missing weather values.

- Hourly

    - Hourly weather data from GSOD will not be imputed

    - Days with more than 5 contiguous hours of missing data will be thrown out

- Daily

    - GSOD daily averages will not be imputed

    - Months with more than than 3 missing days will be thrown out

**Usage**

Usage data generally undergoes significant cleaning prior to release to program administrators or the general public. There are generally three types of missing usage data. First, monthly billing data will be populated with “estimated” reads, when the utility has imputed a likely consumption amount for the month for the purposes of billing, but has not actually recorded a meter reading. Second, there are gaps in AMI meter data, where there may have been a hardware failure or another similar type of infrastructure breakdown where the data was not recorded. Finally, there is the issue of data that goes missing in the process of transferring to program evaluators (in the CalTrack Beta test, two of the zip files holding monthly billing data were corrupted and unreadable). Each of these issues represents a unique challenge and must be dealt with independently.

- For the case of missing values where the cumulative value is in the following period (as in an estimated read), the cumulative number of days between the two periods will be used to generate the UPD for that period
- Missing usage values with no cumulative amount in the following period (such as missing AMI data) will be counted against data sufficiency requirements
- The working group does not offer firm guidance on auditing data sets for completeness, however, a data audit was conducted for the purposes of the Beta test and was found to have identified several missing data issues that would not have otherwise been identified. Thus, a data audit is generally recommended.

**Extreme Values**
Occasionally, the project or consumption data may contain extreme values that are likely the result of a data error, but may also be an indicator of another factor (such as the presence of solar panels). We offer the following guidance:
*Usage*
- Negative values or values with reverse direction of flow should be treated as missing and count against sufficiency criterion. The account will also be flagged for possible solar/net metering if it does not currently contain a net metering flag
- Confirm that IOUs comply with DASMMD.
- AMI data should have the DASMMD pass/fail criterion rerun, with failing values coded as missing. ((highest peak - third highest peak)/third highest peak) <= 1.8
*Project Data*
- Extreme project lengths (gap between project start date and project end date longer than 3 months) should be treated as true and impact estimation only through data sufficiency requirements.

**Sum Check**
If both monthly and AMI data are available for a home, we recommend running a sumcheck and use the DASMMD criterion for pass/fail. If it fails, the home is flagged and treated as having missing usage data so no estimation is run on it.

**Miscoded dates**
- Implausible day values (>31) should be coded as the beginning of month if project start date and end of month if project end date so that the entire month is included in the intervention window
- Implausible month and year values should be flagged and that home not included in estimation.


### *Data sufficiency*

Calculating energy efficiency savings requires a sufficient observation period of energy usage prior to and after an intervention. Generally, annualized models require at least 12 months of usage data on each side of an intervention in order to accurately calculate energy savings. Some models may be able to calculate energy savings with fewer than 12 months of data in the reporting period.

**Usage (Monthly)**
- 12 complete months pre-retrofit for monthly billing data to qualify for estimation or 24 months with up to 2 missing values from different, non-contiguous months
- Post retrofit data sufficiency for estimation will be dealt with in post-estimation model fit criterion
- Total annual savings estimates will require 12 months post-retrofit

**Usage (AMI) (Pending Review)**
- 12 months pre-retrofit
- Post retrofit data sufficiency for estimation will be dealt with in post-estimation model fit criterion
- Total annual savings estimates will require 12 months post-retrofit

**Weather**
If the closest weather station does not report sufficient data, the next closest station should be used to provide weather data for the project.

**Project or Home Characteristics**
Exclude homes with PV
 
### *Data Integration*
Once project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. We recommend using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, we do not offer specific guidance.
- For the purposes of the Beta test, projects were matched to consumption files using a cross reference file supplied by the program administrator.
 
Weather station mapping requires locating the station nearest to the project. Each project file should contain a zip code that allows matching weather stations to projects
- For the purposes of the Beta test, weather station mapping was done using the 86 station standard mapping of zip code to CZ2010 weather files.
 
Unmatched data should be excluded from analysis.
- For the purposes of the Beta test, projects that were unmatched to usage data were listed in CalTRACK for data integrity reporting, but were not included in any estimation procedures and did not have estimated savings.



